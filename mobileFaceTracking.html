<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Yiming</title>
    <link type="text/css"rel="stylesheet"href="desOtherPages.css"/>
    <script src="scripts.js"></script>
  </head>
  <body>
    <div>
      <ul>
        <div align="center">
          <h1>Yiming Lin</h1>
        </div>
        <li><a href="index.html">Home</a></li>
        <li><a href="ai.html">AI</a></li>
        <li><a href="computerVision.html">Computer Vision</a></li>
        <li><a href="mobileFaceTracking.html">Mobile Face Tracking</a></li>
      </ul>
    </div>
    <div class="column side">
      <p></p>
    </div>
    <div class="column middle">
      <h2>Mobile Face Tracking</h2>
      <p>Yiming and his team have gathered material and created a publicly
        available database of smartphone recorded selfie-style videos,
        intended to serve as the backbone of machine learning based face
        tracking algorithms.</br></br>
        The database includes a whopping 95,635 frames, with a bounding
        box of the face “manually labelled”
        on each frame. Out of hundreds of available mobile recordings
        80 videos were carefully selected based
        on various criteria such as the ratio of the time in which
        the face remains in the frame, the speed of
        camera movement or the extremity of lighting conditions.
        This ensures that the selected clips provide
        valuable and realistic content.</br></br>
        Regular object tracking is cannot be sufficiently applied
        for software implementations that require
        face tracking on mobile devices due to the unpredictability
        of certain factors, 4 of which are highlighted
        in Yiming’s paper.</br></br>
        First, face sizes in self recorded mobile videos can change
        drastically as both the device and its target
        are in constant movement, opposed to remaining still as for
        example desktop web cameras do. This continuous
        and quick change of position and location also raises the
        possibility of the target leaving and reentering
        the frame multiple times. The face tracking engine must
        recognise this, as well as keep up with fast camera
        movement. Additionally, it is not uncommon for more than
        one face to be present in a single frame, and it
        is essential that the algorithm differentiates and keeps
        track of each individually.</br></br>
        It is important for researchers to receive feedback and
        recognition from the international academic and
        scientific community, which helps them with future progress.
        MobiFace has been accepted by 14th IEEE International
        Conference on Automatic Face and Gesture Recognition
        (FG 2019). This annual/biannual conference takes place in
        France in 2019, and researchers get a chance to broadcast their findings to the community via demos,
        presentations and exhibitions.
      </p>
    </div>
    <div class="column middle">
      <p></p>
    </div>
    <div class="column side">
      <p></p>
    </div>
    <div class="navbar">
      <ul>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <li><a href="https://twitter.com/yiming_lin__" class="fa fa-twitter"></a></li>
        <li><a href="https://www.linkedin.com/in/yiming-lin-78299b169/?trk=prof-samename-picture&originalSubdomain=uk" class="fa fa-linkedin"></a></li>
      </ul>
    </div>
  </body>
</html>
